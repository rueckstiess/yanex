{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03: Metrics Visualization\n",
    "\n",
    "This notebook demonstrates visualization of experiment metrics using the `plot_metrics()` function.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Using `plot_metrics()` for basic and advanced visualizations\n",
    "- Plotting training curves (single and multiple experiments)\n",
    "- Creating multi-metric dashboards\n",
    "- Comparing experiments with custom labels\n",
    "- Creating subplot grids for parameter comparisons\n",
    "- Statistical aggregation with confidence intervals\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**This notebook uses the same 12 training experiments from Notebooks 01 and 02.**\n",
    "\n",
    "If you haven't already, run this command from the `examples/cli/05_multi_step_metrics/` directory:\n",
    "\n",
    "```bash\n",
    "cd examples/cli/05_multi_step_metrics\n",
    "yanex run train_model.py \\\n",
    "  --param \"epochs=10,20,30\" \\\n",
    "  --param \"learning_rate=logspace(-4, -1, 4)\" \\\n",
    "  --param \"batch_size=32\" \\\n",
    "  --tag results-demo \\\n",
    "  --parallel 0\n",
    "```\n",
    "\n",
    "This creates **12 experiments** (3 epochs × 4 learning rates) with the tag `results-demo`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Import the Results API and configure matplotlib for notebook display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yanex.results as yr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure matplotlib for better display in notebooks\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Basic Usage: Single Experiment Training Curve\n",
    "\n",
    "Let's start with the simplest case - plotting the training curve for a single experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one experiment\n",
    "experiments = yr.get_experiments(tags=[\"results-demo\"], limit=1)\n",
    "exp_id = experiments[0].id\n",
    "\n",
    "print(f\"Plotting experiment: {exp_id}\")\n",
    "print(f\"Epochs: {experiments[0].get_param('epochs')}\")\n",
    "print(f\"Learning rate: {experiments[0].get_param('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training accuracy over time\n",
    "yr.plot_metrics(\"train_accuracy\", ids=[exp_id]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Multiple Metrics: Multi-Metric Dashboard\n",
    "\n",
    "Plot multiple metrics from the same experiment to create a dashboard view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple metrics in separate subplots\n",
    "yr.plot_metrics(\n",
    "    [\"train_accuracy\", \"train_loss\"],\n",
    "    ids=[exp_id],\n",
    "    figsize=(12, 4)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Comparing Multiple Experiments\n",
    "\n",
    "Plot the same metric across multiple experiments to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare training accuracy across all experiments\n",
    "yr.plot_metrics(\n",
    "    \"train_accuracy\",\n",
    "    tags=[\"results-demo\"],\n",
    "    title=\"Training Accuracy Comparison\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "**Note:** The legend shows experiment IDs by default. Let's make this more readable by labeling by learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Custom Labels: Label by Parameter\n",
    "\n",
    "Use `label_by` to label experiments by a parameter value instead of IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label experiments by learning rate\n",
    "yr.plot_metrics(\n",
    "    \"train_accuracy\",\n",
    "    tags=[\"results-demo\"],\n",
    "    label_by=\"learning_rate\",\n",
    "    title=\"Training Accuracy by Learning Rate\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "**Much better!** Now we can see that different learning rates produce different curves, but some experiments share the same learning rate (varying by epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Subplots: Organizing by Parameters\n",
    "\n",
    "Use `subplot_by` to create separate plots for different parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots by number of epochs\n",
    "yr.plot_metrics(\n",
    "    \"train_accuracy\",\n",
    "    tags=[\"results-demo\"],\n",
    "    label_by=\"learning_rate\",\n",
    "    subplot_by=\"epochs\",\n",
    "    figsize=(15, 4),\n",
    "    title=\"Training Accuracy: Learning Rate Effect Across Different Training Durations\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "**Key Insight:** Each subplot shows one training duration (10, 20, or 30 epochs), with different colored lines for each learning rate. This makes it easy to compare the effect of learning rate within each training duration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Custom Subplot Layout\n",
    "\n",
    "Control the subplot arrangement with `subplot_layout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange subplots vertically\n",
    "yr.plot_metrics(\n",
    "    \"train_loss\",\n",
    "    tags=[\"results-demo\"],\n",
    "    label_by=\"learning_rate\",\n",
    "    subplot_by=\"epochs\",\n",
    "    subplot_layout=(3, 1),  # 3 rows, 1 column\n",
    "    figsize=(8, 12)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Multi-Metric + Subplots\n",
    "\n",
    "Combine multiple metrics with subplots for comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x3 grid: 2 metrics × 3 epoch values\n",
    "yr.plot_metrics(\n",
    "    [\"train_accuracy\", \"train_loss\"],\n",
    "    tags=[\"results-demo\"],\n",
    "    label_by=\"learning_rate\",\n",
    "    subplot_by=\"epochs\",\n",
    "    subplot_layout=(2, 3),  # 2 rows (metrics) × 3 columns (epochs)\n",
    "    figsize=(16, 8)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Filtering Experiments\n",
    "\n",
    "Combine `plot_metrics()` with filtering to focus on specific experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get IDs for experiments with 20 epochs using pandas\n",
    "df = yr.compare(tags=[\"results-demo\"])\n",
    "exp_20_epochs = df[df[(\"param\", \"epochs\")] == 20].index.tolist()\n",
    "\n",
    "print(f\"Found {len(exp_20_epochs)} experiments with 20 epochs\")\n",
    "\n",
    "# Plot only those experiments\n",
    "yr.plot_metrics(\n",
    "    \"train_accuracy\",\n",
    "    ids=exp_20_epochs,\n",
    "    label_by=\"learning_rate\",\n",
    "    title=\"Training Accuracy: 20 Epochs Only\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Customizing Plot Appearance\n",
    "\n",
    "Customize labels, titles, and figure size for publication-ready plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom styling\n",
    "yr.plot_metrics(\n",
    "    \"train_accuracy\",\n",
    "    tags=[\"results-demo\"],\n",
    "    label_by=\"learning_rate\",\n",
    "    subplot_by=\"epochs\",\n",
    "    title=\"Neural Network Training Performance\",\n",
    "    xlabel=\"Training Epoch\",\n",
    "    ylabel=\"Accuracy\",\n",
    "    figsize=(15, 4),\n",
    "    grid=True,\n",
    "    legend_position=\"lower right\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Advanced: Post-Processing Plots\n",
    "\n",
    "Use `return_axes=True` to get matplotlib axes for advanced customization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get figure and axes for customization\n",
    "fig, axes = yr.plot_metrics(\n",
    "    \"train_loss\",\n",
    "    tags=[\"results-demo\"],\n",
    "    label_by=\"learning_rate\",\n",
    "    subplot_by=\"epochs\",\n",
    "    figsize=(15, 4),\n",
    "    show=False,\n",
    "    return_axes=True\n",
    ")\n",
    "\n",
    "# Add custom annotations\n",
    "for ax in axes:\n",
    "    # Add horizontal line at target loss\n",
    "    ax.axhline(y=0.3, color='red', linestyle='--', alpha=0.5, label='Target Loss')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Statistical Aggregation (Advanced)\n",
    "\n",
    "For this section, we'll simulate repeated runs by treating experiments with the same learning rate as \"replicate runs.\" In real scenarios, you'd use `group_by` to aggregate over true random seeds or cross-validation folds.\n",
    "\n",
    "**Note:** The `group_by` parameter aggregates experiments and shows mean/confidence intervals. This is most useful when you have multiple runs with different random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, let's show what this would look like conceptually\n",
    "# In practice, you'd use: group_by=\"random_seed\", label_by=\"learning_rate\"\n",
    "\n",
    "print(\"Statistical aggregation with group_by is most useful when you have:\")\n",
    "print(\"  - Multiple runs with different random seeds\")\n",
    "print(\"  - Cross-validation folds\")\n",
    "print(\"  - Replicate experiments\")\n",
    "print(\"\\nExample usage:\")\n",
    "print(\"  yr.plot_metrics(\")\n",
    "print(\"      'accuracy',\")\n",
    "print(\"      tags=['repeated_runs'],\")\n",
    "print(\"      group_by='random_seed',     # Aggregate over seeds\")\n",
    "print(\"      label_by='learning_rate',   # Color by LR\")\n",
    "print(\"      show_ci=True,               # Show 95% confidence interval\")\n",
    "print(\"      show_individuals=True       # Show individual runs faintly\")\n",
    "print(\"  )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Building Blocks: Using Lower-Level APIs\n",
    "\n",
    "For maximum flexibility, use the underlying building blocks to create custom visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import building blocks\n",
    "from yanex.results.viz import extract_metrics_df\n",
    "\n",
    "# Get experiments\n",
    "experiments = yr.get_experiments(tags=[\"results-demo\"])\n",
    "\n",
    "# Extract metrics to pandas DataFrame\n",
    "df = extract_metrics_df(experiments, [\"train_accuracy\", \"train_loss\"])\n",
    "\n",
    "print(f\"Extracted {len(df)} metric records from {df['experiment_id'].nunique()} experiments\")\n",
    "print(f\"\\nDataFrame columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can use any pandas operations!\n",
    "# For example, compute rolling average\n",
    "df_with_smooth = df.copy()\n",
    "df_with_smooth['train_accuracy_smooth'] = (\n",
    "    df_with_smooth.groupby('experiment_id')['train_accuracy']\n",
    "    .transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    ")\n",
    "\n",
    "# Plot with matplotlib\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for exp_id, exp_df in df_with_smooth.groupby('experiment_id'):\n",
    "    lr = exp_df['learning_rate'].iloc[0]\n",
    "    ax.plot(exp_df['step'], exp_df['train_accuracy_smooth'], \n",
    "           label=f'lr={lr:.4f}', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('Training Accuracy (smoothed)')\n",
    "ax.set_title('Custom Plot: Smoothed Training Curves')\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## Comparing Best vs Worst\n",
    "\n",
    "Visualize the difference between the best and worst performing experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best and worst experiments\n",
    "all_experiments = yr.get_experiments(tags=[\"results-demo\"])\n",
    "\n",
    "# Get final accuracy for each\n",
    "final_accuracies = [\n",
    "    (exp.id, exp.get_metric('train_accuracy')[-1], \n",
    "     exp.get_param('learning_rate'), exp.get_param('epochs'))\n",
    "    for exp in all_experiments\n",
    "]\n",
    "\n",
    "# Sort by accuracy\n",
    "final_accuracies.sort(key=lambda x: x[1])\n",
    "\n",
    "worst_id, worst_acc, worst_lr, worst_epochs = final_accuracies[0]\n",
    "best_id, best_acc, best_lr, best_epochs = final_accuracies[-1]\n",
    "\n",
    "print(f\"Worst: {worst_id} - {worst_acc:.4f} (lr={worst_lr:.4f}, epochs={worst_epochs})\")\n",
    "print(f\"Best:  {best_id} - {best_acc:.4f} (lr={best_lr:.4f}, epochs={best_epochs})\")\n",
    "\n",
    "# Plot comparison\n",
    "yr.plot_metrics(\n",
    "    [\"train_accuracy\", \"train_loss\"],\n",
    "    ids=[worst_id, best_id],\n",
    "    subplot_layout=(2, 1),\n",
    "    figsize=(10, 8),\n",
    "    title=\"Best vs Worst Experiment\"\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "✅ **Basic Plotting:**\n",
    "- `yr.plot_metrics(metric, ids=[...])` - Single experiment\n",
    "- `yr.plot_metrics([metric1, metric2], ...)` - Multiple metrics\n",
    "- `yr.plot_metrics(metric, tags=[...])` - Multiple experiments\n",
    "\n",
    "✅ **Organization:**\n",
    "- `label_by` - Determines line colors and legend labels\n",
    "- `subplot_by` - Creates separate subplots by parameter\n",
    "- `subplot_layout` - Controls subplot arrangement (rows, cols)\n",
    "\n",
    "✅ **Customization:**\n",
    "- `title`, `xlabel`, `ylabel` - Custom labels\n",
    "- `figsize` - Figure dimensions\n",
    "- `return_axes=True` - Get axes for advanced customization\n",
    "- `show=False` - Suppress immediate display\n",
    "\n",
    "✅ **Advanced:**\n",
    "- `group_by` - Statistical aggregation (for replicate runs)\n",
    "- `show_ci`, `show_std` - Confidence intervals and standard deviation\n",
    "- Building blocks: `extract_metrics_df()` for custom analysis\n",
    "\n",
    "✅ **Best Practices:**\n",
    "- Use `label_by` to make legends readable\n",
    "- Use `subplot_by` to organize comparisons\n",
    "- Combine with pandas for filtering\n",
    "- Use building blocks for custom visualizations\n",
    "\n",
    "## Summary\n",
    "\n",
    "The `plot_metrics()` function provides a flexible, progressive API:\n",
    "- **Beginners:** Simple one-liners for common plots\n",
    "- **Intermediate:** Parameters for organizing and labeling\n",
    "- **Advanced:** Building blocks for custom analysis\n",
    "\n",
    "All plots use publication-ready defaults (colorblind-safe, clean styling) but can be fully customized when needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
