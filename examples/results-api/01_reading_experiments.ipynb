{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Reading Experiments\n",
    "\n",
    "This notebook demonstrates the basics of reading experiment data using the Yanex Results API.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- Importing and using the Results API\n",
    "- Getting single and multiple experiments\n",
    "- Filtering experiments by tags\n",
    "- Exploring the `Experiment` object\n",
    "- Reading parameters and metrics\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "**Before running this notebook**, you need to create sample experiments using the multi-step metrics CLI example with a parameter sweep.\n",
    "\n",
    "Run this command from the `examples/cli/05_multi_step_metrics/` directory:\n",
    "\n",
    "```bash\n",
    "cd examples/cli/05_multi_step_metrics\n",
    "yanex run train_model.py \\\n",
    "  --param \"epochs=10,20,30\" \\\n",
    "  --param \"learning_rate=logspace(-4, -1, 4)\" \\\n",
    "  --param \"batch_size=32\" \\\n",
    "  --tag results-demo \\\n",
    "  --parallel 0\n",
    "```\n",
    "\n",
    "This creates **12 experiments** in parallel (3 epochs × 4 learning rates) with the tag `results-demo`. We'll use this tag to filter and analyze these specific experiments throughout this notebook.\n",
    "\n",
    "**What this trains:**\n",
    "- A simple neural network training simulation\n",
    "- Logs metrics at each epoch: `train_loss`, `train_accuracy`\n",
    "- Occasionally logs validation metrics: `val_loss`, `val_accuracy`\n",
    "- Parameters: `epochs`, `learning_rate`, `batch_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Results API\n",
    "\n",
    "The Results API is available under `yanex.results`. By convention, we import it as `yr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yanex.results as yr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Our Training Experiments\n",
    "\n",
    "Use `get_experiments()` with the `tags` filter to retrieve our 12 training experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get our 12 experiments using the tag\n",
    "experiments = yr.get_experiments(tags=[\"results-demo\"])\n",
    "\n",
    "print(f\"Retrieved {len(experiments)} experiments\")\n",
    "print(\"\\nExperiment IDs:\")\n",
    "for exp in experiments[:5]:\n",
    "    print(f\"  {exp.id}: {exp.status}\")\n",
    "if len(experiments) > 5:\n",
    "    print(f\"  ... and {len(experiments) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a Single Experiment: `get_experiment(id)`\n",
    "\n",
    "When you know the experiment ID, use `get_experiment()` to retrieve it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the first experiment as an example\n",
    "experiment_id = experiments[0].id\n",
    "exp = yr.get_experiment(experiment_id)\n",
    "\n",
    "print(f\"Retrieved experiment: {exp.id}\")\n",
    "print(f\"Status: {exp.status}\")\n",
    "print(f\"Tags: {', '.join(exp.tags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Experiment Object\n",
    "\n",
    "The `Experiment` object provides access to all experiment data:\n",
    "\n",
    "### Metadata Properties\n",
    "- `id` - Unique 8-character hex ID\n",
    "- `name` - Human-readable name\n",
    "- `description` - Experiment description\n",
    "- `status` - Status (completed, failed, cancelled, running)\n",
    "- `tags` - List of tags\n",
    "- `started_at` - Start timestamp (datetime)\n",
    "- `completed_at` - End timestamp (datetime)\n",
    "- `duration` - Duration (timedelta)\n",
    "- `script_path` - Path to script\n",
    "- `experiment_dir` - Path to experiment directory\n",
    "\n",
    "### Data Access Methods\n",
    "- `get_params()` - Get all parameters as dict\n",
    "- `get_param(name)` - Get single parameter value\n",
    "- `get_metrics()` - Get all metrics (list of dicts with timestamps)\n",
    "- `get_metric(name)` - Get specific metric value(s)\n",
    "- `get_artifacts()` - Get list of artifact paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore an experiment in detail\n",
    "exp = experiments[0]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Experiment: {exp.id}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Metadata\n",
    "print(f\"\\nStatus: {exp.status}\")\n",
    "print(f\"Tags: {', '.join(exp.tags)}\")\n",
    "\n",
    "# Timing\n",
    "print(f\"\\nStarted: {exp.started_at}\")\n",
    "print(f\"Completed: {exp.completed_at}\")\n",
    "print(f\"Duration: {exp.duration}\")\n",
    "\n",
    "# Paths\n",
    "print(f\"\\nScript: {exp.script_path}\")\n",
    "print(f\"Directory: {exp.experiment_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Parameters\n",
    "\n",
    "Parameters are the configuration values used to run the experiment. Our training experiments have three parameters: `epochs`, `learning_rate`, and `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all parameters as a dictionary\n",
    "params = exp.get_params()\n",
    "\n",
    "print(\"All parameters:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Get specific parameters\n",
    "epochs = exp.get_param(\"epochs\")\n",
    "learning_rate = exp.get_param(\"learning_rate\")\n",
    "batch_size = exp.get_param(\"batch_size\")\n",
    "\n",
    "print(\"\\nTraining configuration:\")\n",
    "print(f\"  Epochs: {epochs}\")\n",
    "print(f\"  Learning rate: {learning_rate}\")\n",
    "print(f\"  Batch size: {batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Metrics\n",
    "\n",
    "Metrics are the results logged during experiment execution. Our training script logs:\n",
    "- `train_loss` - Training loss at each epoch\n",
    "- `train_accuracy` - Training accuracy at each epoch  \n",
    "- `val_loss` - Validation loss (logged occasionally)\n",
    "- `val_accuracy` - Validation accuracy (logged occasionally)\n",
    "\n",
    "**Two ways to access metrics:**\n",
    "1. `get_metrics()` - Returns list of metric dictionaries (includes timestamps, steps)\n",
    "2. `get_metric(name)` - Returns value(s) for a specific metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all metrics (full detail with timestamps and steps)\n",
    "all_metrics = exp.get_metrics()\n",
    "\n",
    "print(f\"Total metric entries logged: {len(all_metrics)}\")\n",
    "print(\"\\nFirst 3 metric entries:\")\n",
    "\n",
    "for metric in all_metrics[:3]:\n",
    "    print(f\"\\n  Step {metric['step']} @ {metric['timestamp']}:\")\n",
    "    for key, value in metric.items():\n",
    "        if key not in [\"step\", \"timestamp\", \"last_updated\"]:\n",
    "            print(f\"    {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Specific Metrics\n",
    "\n",
    "Use `get_metric()` to extract specific metrics across all steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training loss across all epochs\n",
    "train_loss = exp.get_metric(\"train_loss\")\n",
    "train_accuracy = exp.get_metric(\"train_accuracy\")\n",
    "\n",
    "print(f\"Training progression ({len(train_loss)} epochs):\")\n",
    "print(f\"\\nTrain Loss: {train_loss}\")\n",
    "print(f\"Train Accuracy: {train_accuracy}\")\n",
    "\n",
    "# Show final values\n",
    "print(\"\\nFinal metrics:\")\n",
    "print(f\"  Train Loss: {train_loss[-1]:.4f}\")\n",
    "print(f\"  Train Accuracy: {train_accuracy[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Multiple Experiments\n",
    "\n",
    "Let's look at the parameter configurations and final performance across all 12 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All 12 Training Experiments\")\n",
    "print(\"=\" * 90)\n",
    "print(\n",
    "    f\"{'ID':<12} {'Epochs':<8} {'Learn Rate':<12} {'Final Loss':<12} {'Final Acc':<12}\"\n",
    ")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for exp in experiments:\n",
    "    epochs = exp.get_param(\"epochs\")\n",
    "    lr = exp.get_param(\"learning_rate\")\n",
    "\n",
    "    # Get final metrics\n",
    "    train_loss = exp.get_metric(\"train_loss\")\n",
    "    train_acc = exp.get_metric(\"train_accuracy\")\n",
    "\n",
    "    final_loss = train_loss[-1]\n",
    "    final_acc = train_acc[-1]\n",
    "\n",
    "    print(\n",
    "        f\"{exp.id:<12} {epochs:<8} {lr:<12.6f} {final_loss:<12.4f} {final_acc:<12.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Best Experiment\n",
    "\n",
    "Let's find which hyperparameter combination gave the best final training accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_best() to find the experiment with highest train_accuracy\n",
    "best_exp = yr.get_best(\"train_accuracy\", maximize=True, tags=[\"results-demo\"])\n",
    "\n",
    "print(\"Best Experiment:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ID: {best_exp.id}\")\n",
    "print(\"Hyperparameters:\")\n",
    "print(f\"  Epochs: {best_exp.get_param('epochs')}\")\n",
    "print(f\"  Learning rate: {best_exp.get_param('learning_rate'):.6f}\")\n",
    "print(f\"  Batch size: {best_exp.get_param('batch_size')}\")\n",
    "print(\"Final Performance:\")\n",
    "print(f\"  Train Loss: {best_exp.get_metric('train_loss')[-1]:.4f}\")\n",
    "print(f\"  Train Accuracy: {best_exp.get_metric('train_accuracy')[-1]:.4f}\")\n",
    "print(f\"Duration: {best_exp.duration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by Status\n",
    "\n",
    "You can filter experiments by various criteria to focus your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter our experiments by status\n",
    "completed = yr.get_experiments(tags=[\"results-demo\"], status=\"completed\")\n",
    "failed = yr.get_experiments(tags=[\"results-demo\"], status=\"failed\")\n",
    "\n",
    "print(\"Status breakdown:\")\n",
    "print(f\"  Completed: {len(completed)}/12\")\n",
    "print(f\"  Failed: {len(failed)}/12\")\n",
    "\n",
    "if failed:\n",
    "    print(\"\\nFailed experiments:\")\n",
    "    for exp in failed:\n",
    "        print(\n",
    "            f\"  {exp.id}: {exp.get_param('epochs')} epochs, lr={exp.get_param('learning_rate'):.6f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "✅ **Results API Basics:**\n",
    "- `import yanex.results as yr` - Import convention\n",
    "- `yr.get_experiments(tags=[...])` - Query experiments by tag\n",
    "- `yr.get_experiment(id)` - Get single experiment by ID\n",
    "- Filter with `status`, `tags`, `name`, etc.\n",
    "\n",
    "✅ **Experiment Object:**\n",
    "- Metadata properties: `id`, `status`, `tags`, `started_at`, `duration`, etc.\n",
    "- Parameter access: `get_params()`, `get_param(name)`\n",
    "- Metric access: `get_metrics()` (with timestamps), `get_metric(name)` (values only)\n",
    "\n",
    "✅ **Multi-Step Metrics:**\n",
    "- `get_metric(name)` returns a list of values (one per step)\n",
    "- Access final value with `[-1]`\n",
    "- `get_metrics()` includes full step and timestamp information\n",
    "\n",
    "✅ **Use Cases:**\n",
    "- Reading individual experiment results\n",
    "- Extracting specific parameters or metrics\n",
    "- Finding best experiments manually\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **Notebook 02: Filtering and Comparing** to learn:\n",
    "- Using `compare()` to create pandas DataFrames\n",
    "- Analyzing multiple experiments efficiently\n",
    "- Advanced filtering patterns\n",
    "- Finding optimal hyperparameters with pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
